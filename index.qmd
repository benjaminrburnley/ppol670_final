---
title: "Redistricting Project: Florida"
author: "Ben Burnley, Sean Conner, Gustavo Murillo Velazquez, & Katie Ward"
format: 
  html:
    self-contained: true
---
# Introduction 
```{r}
#| echo: false
#| message: false
#| warning: false
#| output: false

# libraries 
library(tidyverse)
library(tidymodels)
library(spatialsample)
library(sf)
library(patchwork)
library(janitor)

# data import 
dist_18 = st_read("data/fl_cong_2015_to_2021/fl_cong_2015_to_2021.shp") %>%  # 2015-2021 Congressional District Map 
  clean_names()
dist_22 = st_read("data/fl_cong_adopted_2022/P000C0109.shp") %>%  # 2022 Congressional District Map 
 clean_names() %>% 
  st_transform(crs = st_crs(dist_18))

# voting data at precinct level for 2022
vote_18 = st_read("data/fl_vest_18/fl_vest_18.shp") %>% 
  clean_names() %>% 
  st_transform(crs = st_crs(dist_18))

# filter for valid geometries 
vote_18 = vote_18[st_is_valid(vote_18) == TRUE,]

# transform the crs of dist 20 to match 22 
dist_18 = st_transform(dist_18, crs = st_crs(dist_22))

# check crs 
st_crs(vote_18) == st_crs(dist_18)
st_crs(vote_18) == st_crs(dist_22)
```

This project examines the effect of the redistricting process on voter turnout. We use the change in maps from 2020 to 2022 in the state of Florida as a case study to examine this effect. 

```{r}
#| warning: false
#| message: false
#| code-fold: true

# plots comparing two maps 
plot1 = ggplot(dist_18)+
  geom_sf(fill = "white")+
  theme_void()+
  ggtitle("2015-2021 Map")

plot2 = ggplot(dist_22)+
  geom_sf(fill = "white")+
  theme_void()+
 ggtitle("2022 Map")

plot1 + plot2
```

```{r}
#| warning: false
#| messages: false
#| code-fold: true

# plot of precincts 
ggplot(vote_18)+
  geom_sf()+
  theme_void()
```


# How to use Redistricting Data Hub's API

The data for this project comes from Redistricting Data Hub, a nonpartisan organization that collects a number of sources of data related to redistricting efforts with the goal of providing resources and facilitating participation in the process. For each state, RDH collects a number of data sets related to district boundaries, election results, voter files, as well as demographics for each state from the American Community Survey. This level of access to a single stash of data makes RDH an ideal source of data for government groups, academics, and anyone interested in the redistricting process to access all the data they need to do analysis. 

To aid in this, the Redistricting Data Hub has an API to locate and download all files related to a given state. We decided this would be the best approach to getting the data necessary for our analysis of Florida's redistricting process. Redistricting Data Hub has a slightly tedious process for accessing the API compared to other sources we have used. First, the individual requesting access must fill out a Google form located on RDH's website. Part of this process is a prompt to verify your identity by emailing a picture of the applicant holding a government issued ID. To complete the process someone at RDH must review your application and verify your identity. This process is more restrictive than most APIs and might be a bit cumbersome for some research applications. 

From here, you have access to a GitHub repository where you can download a Python script (in the code blocks below) to download all the data for a state of interest. Researchers have the ability of downloading up to 4 states at a time, making this process relatively scalable depending upon the scope of your research. We followed these steps to download all files related to the state of Florida in Redistricting Data Hub's database. 


# Data Processing 

For our analysis, we ended up primarily relying on three data sets. The first two are the Congressional District maps from Florida's Redistricting process. The first map was utilized for all elections between 2018 and 2020. The second map is the new map that was redrawn for the 2020 redistricting process and used in the 2022 midterms. Last, we used the precinct level voting results from the Voting and Elections Science Team (VEST). During this process we ran into one of the first hurdles in pursuing our ideal project. The plan had been to compare precinct level results across two maps. While precincts are often redrawn with Congressional districts, our aim was to see if a precinct had been drawn into a new district during redistricting, quantify the degree to which this was the case, and then see how this impacted factors like turnout and partisan vote. Unfortunately for our project, no one has joined 2022 midterm results with precinct shapefiles yet and so this approach is not yet feasible. We briefly considered using the only available location data in the 2022 precinct data, polling location name and county, to geocode polling location into point data. This would at least let us compare the district the precinct was within during the 2018 cycle to the district the polling location was in during the 2022 cycle. With only location name for over 6,000 precincts this felt both unfeasible and susceptible to mistakes. Had the data included precinct address, we could have coded point data using `tidygeocoder`.

From here, we decided that the best approach would be to try to say something about the redistricting process given the data we had. The process we decided on was to determine whether a precinct had been  

```{r}
#| warning: false
#| message: false

# loop for creating district 2018 objects 
districts_18 <- list()

for(i in 1:27){
districts_18[[i]] <- assign(paste0("dist_18_",i), filter(dist_18, district == i))
}

# loop for creating district 2022 objects
districts_22 <- list()

for(i in 1:28){
districts_22[[i]] <-  assign(paste0("dist_22_", i), filter(dist_22, district == i))
}

# create district columns for 2018 map 
for(i in 1:27){
  assign(paste0("within_18_",i), st_within(vote_18, districts_18[[i]], sparse = FALSE))
}

# create district columns for 2022 map 
for(i in 1:28){
  assign(paste0("within_22_",i), st_within(vote_18, districts_22[[i]], sparse = FALSE))
}

# collect columns
dist18_df = data.frame(dist_1 = within_18_1,
                   dist_2 = within_18_2,
                   dist_3 =  within_18_3,
                   dist_4 = within_18_4,
                   dist_5 = within_18_5,
                   dist_6 = within_18_6,
                   dist_7 = within_18_7,
                   dist_8 = within_18_8,
                   dist_9 = within_18_9,
                   dist_10 = within_18_10,
                   dist_11 = within_18_11,
                   dist_12 = within_18_12,
                   dist_13 = within_18_13,
                   dist_14 = within_18_14,
                   dist_15 = within_18_15,
                   dist_16 = within_18_16,
                   dist_17 = within_18_17,
                   dist_18 = within_18_18,
                   dist_19 = within_18_19,
                   dist_20 = within_18_20,
                   dist_21 = within_18_21,
                   dist_22 = within_18_22,
                   dist_23 = within_18_23,
                   dist_24 = within_18_24,
                   dist_25 = within_18_25,
                   dist_26 = within_18_26,
                   dist_27 = within_18_27)

data_18 = dist18_df %>% 
  mutate(district_18 = case_when(
    dist_1 == TRUE ~ "District 1",
    dist_2 == TRUE ~ "District 2",
    dist_3 == TRUE ~ "District 3", 
    dist_4 == TRUE ~ "District 4",
    dist_5 == TRUE ~ "District 5", 
    dist_6 == TRUE ~ "District 6", 
    dist_7 == TRUE ~ "District 7", 
    dist_8 == TRUE ~ "District 8",
    dist_9 == TRUE ~ "District 9", 
    dist_10 == TRUE ~ "District 10", 
    dist_11 == TRUE ~ "District 11", 
    dist_12 == TRUE ~ "District 12", 
    dist_13 == TRUE ~ "District 13", 
    dist_14 == TRUE ~ "District 14", 
    dist_15 == TRUE ~ "District 15", 
    dist_16 == TRUE ~ "District 16",
    dist_17 == TRUE ~ "District 17", 
    dist_18 == TRUE ~ "District 18", 
    dist_19 == TRUE ~ "District 19",
    dist_20 == TRUE ~ "District 20", 
    dist_21 == TRUE ~ "District 21", 
    dist_22 == TRUE ~ "District 22",
    dist_23 == TRUE ~ "District 23", 
    dist_24 == TRUE ~ "District 24", 
    dist_25 == TRUE ~ "District 25", 
    dist_26 == TRUE ~ "District 26",
    dist_27 == TRUE ~ "District 27", 
    TRUE ~ "Split"
  ))

dist22_df = data.frame(dist_1 = within_22_1,
                   dist_2 = within_22_2,
                   dist_3 =  within_22_3,
                   dist_4 = within_22_4,
                   dist_5 = within_22_5,
                   dist_6 = within_22_6,
                   dist_7 = within_22_7,
                   dist_8 = within_22_8,
                   dist_9 = within_22_9,
                   dist_10 = within_22_10,
                   dist_11 = within_22_11,
                   dist_12 = within_22_12,
                   dist_13 = within_22_13,
                   dist_14 = within_22_14,
                   dist_15 = within_22_15,
                   dist_16 = within_22_16,
                   dist_17 = within_22_17,
                   dist_18 = within_22_18,
                   dist_19 = within_22_19,
                   dist_20 = within_22_20,
                   dist_21 = within_22_21,
                   dist_22 = within_22_22,
                   dist_23 = within_22_23,
                   dist_24 = within_22_24,
                   dist_25 = within_22_25,
                   dist_26 = within_22_26,
                   dist_27 = within_22_27,
                   dist_28 = within_22_28)

data_22 = dist22_df %>% 
  mutate(district_22 = case_when(
    dist_1 == TRUE ~ "District 1",
    dist_2 == TRUE ~ "District 2",
    dist_3 == TRUE ~ "District 3", 
    dist_4 == TRUE ~ "District 4",
    dist_5 == TRUE ~ "District 5", 
    dist_6 == TRUE ~ "District 6", 
    dist_7 == TRUE ~ "District 7", 
    dist_8 == TRUE ~ "District 8",
    dist_9 == TRUE ~ "District 9", 
    dist_10 == TRUE ~ "District 10", 
    dist_11 == TRUE ~ "District 11", 
    dist_12 == TRUE ~ "District 12", 
    dist_13 == TRUE ~ "District 13", 
    dist_14 == TRUE ~ "District 14", 
    dist_15 == TRUE ~ "District 15", 
    dist_16 == TRUE ~ "District 16",
    dist_17 == TRUE ~ "District 17", 
    dist_18 == TRUE ~ "District 18", 
    dist_19 == TRUE ~ "District 19",
    dist_20 == TRUE ~ "District 20", 
    dist_21 == TRUE ~ "District 21", 
    dist_22 == TRUE ~ "District 22",
    dist_23 == TRUE ~ "District 23", 
    dist_24 == TRUE ~ "District 24", 
    dist_25 == TRUE ~ "District 25", 
    dist_26 == TRUE ~ "District 26",
    dist_27 == TRUE ~ "District 27", 
    dist_28 == TRUE ~ "District 28",
    TRUE ~ "Split"
  ))

# combine datasets and create redrawn column
data_both = data_18 %>% 
  bind_cols(data_22) %>% 
  mutate(redrawn = if_else(district_18 == district_22, FALSE, TRUE)) %>% 
  dplyr::select(district_18, district_22, redrawn)

# data frame with column indicating whether a precinct was drawn into a new district
data = vote_18 %>% 
  bind_cols(data_both)
```

# Visualizations 

** SECTION ON DATA VISUALIZATIONS ** 
```{r}
#| warning: false
#| message: false
#| code-fold: true

# map of overlapping geometries 
ggplot()+
  geom_sf(data = dist_18, color = "red", alpha = 0, lwd = 1) +
  geom_sf(data = dist_22, color = "blue", alpha = 0, lwd = 0.5) + 
  theme_void()+
  labs(
    title = "Overlay of Old and New Districts ",
    subtitle = "Red lines are old borders, purple lines are unchanged, blue lines are new borders",
  )+
  theme(
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(face = "italic", size = "8")
  )

# map of districts and whether they were redrawn
ggplot(data = data, mapping = aes(fill = redrawn)) +
  geom_sf(alpha = 0.9, color = NA) +
  theme_void() +
  labs(title = "Redrawn Precincts",
       fill = "Was the Precinct Redrawn?") +
  theme(plot.title = element_text(face = "bold"),
        legend.title = element_text(face = "italic", size = 8))

```

The dispersion of redrawn precincts in Florida does not appear to be random where those in Central Florida were redistricted more than those on the coasts. We suspect underlying political motivations in Congressional redistricting. In order to test this assumption, we deploy a machine learning model with the following predictors: [fill in with variables we settle on]

# Preparing the Dataset for Modeling

```{r}

# checking for class imbalances
summary(data$redrawn)

# select variables for model and change types for optimal use
redrawn_sf = data %>%
  select(pct_std, county, precinct,
         g18ussrsco, g18ussdnel, g18govdgil, g18govrdes,
         redrawn, -geometry) %>%
  mutate_if(is.logical, factor) %>%
  st_drop_geometry()

redrawn_sf

```

# Machine Learning Model 

** SECTION ON MACHINE LEARNING PROCESS **

```{r}
#| warning: false
#| message: false
#| code-fold: true

set.seed(20230510)

# set up v fold cross validation
folds = vfold_cv(redrawn_sf, folds = 10, repeats = 1)

# split precinct data into training and testing data
split = initial_split(redrawn_sf, strata = redrawn)
data_train = training(split)
data_test = testing(split)

# create recipe
redrawn_rec = recipe(redrawn ~ ., data = data_train) %>%
  # update roles of variables to not be used in the model but want to keep
  # for potentiala future use
  update_role(pct_std, county, precinct, new_role = "ID") %>%
  # standardize numeric variables
  step_center(all_numeric_predictors()) %>%
  step_scale(all_numeric_predictors()) %>%
  prep()

```

The first machine learning model will be a simple logistic regression in order to set a baseline of performance.

```{r}

# set basic logistic regression model
logistic_mod = logistic_reg(mode = "classification",
                             engine = "glm")

# feed recipe and model to a logistic regression workflow
logistic_wf = workflow() %>%
  add_recipe(redrawn_rec) %>%
  add_model(logistic_mod)

# implement cross validation to evaluate models
logistic_cv = logistic_wf %>%
  fit_resamples(resamples = folds, control = control_resamples(save_pred = TRUE))

# see available metrics
logistic_cv %>% unnest(.metrics)
# show best metrics
logistic_cv %>% collect_metrics()
# pull out best model according to ROC metric
logistic_best_roc = logistic_cv %>%
  select_best(metric = "roc_auc")

# implement final workflow based on best model
logistic_final_wf = finalize_workflow(logistic_wf,
                                       parameters = logistic_best_roc)

```
After having set a baseline of performance with the logistic regression model, implemented with 10-fold cross validation, the next step is to deploy several other models and evaluate their performance relative to this baseline. The following Random Forest model will include the same cross-validation as well as hyperparameter tuning.

```{r}

# set model specifications
rf_tune_spec = rand_forest(mtry = tune(),
            trees = 100,
            min_n = tune()) %>%
  set_mode("classification") %>%
  set_engine("ranger")

# feed same recipe and Random Forest model to new workflow
rf_wf = workflow() %>%
  add_recipe(redrawn_rec) %>%
  add_model(rf_tune_spec)

# tune hyperparameters
rf_tune_res = tune_grid(
  rf_wf,
  resamples = folds,
  grid = 20
)

rf_tune_res %>% unnest(.metrics)
rf_tune_res %>% collect_metrics()
rf_tune_res %>% select_best("roc_auc")

# based on best ROC, mtry = 1 and min_n = 28
# create grid for ranges with these values
rf_grid_reg = grid_regular(
  mtry(range = c(0,5)),
  min_n(range = c(20, 40)),
  levels = 5
)

# tune hyperparameters again based on new grid
rf_grid_reg_res = tune_grid(
  rf_wf,
  resamples = folds,
  grid = rf_grid_reg
)

rf_grid_reg_res %>% unnest(.metrics)
rf_grid_reg_res %>% collect_metrics()
# pull out best performing hyperparameters based on ROC metric
rf_best_roc = rf_grid_reg_res %>%
  select_best("roc_auc")

rf_final_mod = finalize_model(
  rf_tune_spec,
  rf_best_roc
)

rf_final_mod %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(redrawn ~ ., data = juice(redrawn_rec) %>%
        select(-pct_std, -county, -precinct)) %>%
  vip::vip(geom = "point")

rf_final_wf = workflow() %>%
  add_recipe(redrawn_rec) %>%
  add_model(rf_final_mod)

rf_final_fit = fit(rf_final_wf, data_train)

```

## Estimate the Out of Sample Error Rate

```{r}

data_test_predictions = predict(rf_final_fit, new_data = data_test)

prediction = bind_cols(
  `actual_redrawn` = data_test$redrawn,
  `predicted_redrawn` = data_test_predictions$.pred_class
)

accuracy(prediction, truth = actual_redrawn, estimate = predicted_redrawn)
recall(prediction, truth = actual_redrawn, estimate = predicted_redrawn)
specificity(prediction, truth = actual_redrawn, estimate = predicted_redrawn)



```

Because Districts 18 and 21 seemed to have the highest predictive power in the model, we dug a little deeper at some of their demographic information to see if we could learn more context for those areas. The following charts show the overall population percentages of major races in the state and then specific population estimates for Districts 18 and 21. 

```{r}
cvap_18 <- st_read("/Users/katieward/Desktop/Georgetown/Spring_2023/Data_Science/ppol670_final/ppol670_final/data/fl_cvap_2018_cd/fl_cvap_2018_cd.shp") 

# Data Visualization of Black population
cvap_18$percent <- (cvap_18$ALL_BLK18 / cvap_18$ALL_TOT18) * 100

black_percent <- ggplot() +
  geom_sf(data = cvap_18, aes(fill = percent)) +
  scale_fill_gradient(name = "Percentage", 
                      low = "white", high = "darkblue",
                      breaks = seq(0, 100, by = 10),
                      labels = paste0(seq(0, 100, by = 10), "%")) +
  theme_void() +
  labs(title = "Black Population 2018 by Cong. District",
       fill = "Percentage of District Population") +
  theme(plot.title = element_text(face = "bold"),
        legend.title = element_text(face = "italic", size = 8))


# Data Visualization of Hispanic Population
cvap_18$percenthisp <- (cvap_18$ALL_HSP18 / cvap_18$ALL_TOT18) * 100

hisp_percent <- ggplot() +
  geom_sf(data = cvap_18, aes(fill = percenthisp)) +
  scale_fill_gradient(name = "Percentage", 
                      low = "white", high = "darkgreen",
                      breaks = seq(0, 100, by = 10),
                      labels = paste0(seq(0, 100, by = 10), "%")) +
  theme_void() +
  labs(title = "Hispanic Population 2018 by Cong. District",
       fill = "Percentage of District Population") +
  theme(plot.title = element_text(face = "bold"),
        legend.title = element_text(face = "italic", size = 8))

hisp_percent

# Data Visualization of White Population

cvap_18$percentwhite <- (cvap_18$ALL_WHT18 / cvap_18$ALL_TOT18) * 100

white_percent <- ggplot() +
  geom_sf(data = cvap_18, aes(fill = percentwhite)) +
  scale_fill_gradient(name = "Percentage", 
                      low = "white", high = "darkred",
                      breaks = seq(0, 100, by = 10),
                      labels = paste0(seq(0, 100, by = 10), "%")) +
  theme_void() +
  labs(title = "White Population 2018 by Cong. District",
       fill = "Percentage of District Population") +
  theme(plot.title = element_text(face = "bold"),
        legend.title = element_text(face = "italic", size = 8))

white_percent

# Data Vis. of Race Estimates for District 18
cvap_dist18 <- cvap_18 %>%
  filter(DIST=="Congressional District 18 (116th Congress)") %>%
  st_drop_geometry() %>%
  select(ALL_TOT18, ALL_AIA18, ALL_ASN18, ALL_BLK18, ALL_NHP18, ALL_WHT18, ALL_2OM18, ALL_HSP18) %>%
  rename("Total Population Est." = ALL_TOT18, 
          "Native American" = ALL_AIA18, 
         "Black" = ALL_BLK18,
         "Pacific Islander" = ALL_NHP18,
         "White" = ALL_WHT18,
         "Two or More Races" = ALL_2OM18,
         "Hispanic" = ALL_HSP18,
         "Asian" = ALL_ASN18)

cvap_dist18 <- cvap_dist18 %>% 
  pivot_longer(everything(),
                    names_to='Race',
                    values_to='Count')

cvap_dist18$Race <- reorder(cvap_dist18$Race, -cvap_dist18$Count)

dist18_raceplot <- cvap_dist18 %>%
ggplot(aes(x = Race, y = Count, fill= Count)) +
  geom_bar(stat = "identity") +
  labs(title = "Population Estimate of District 18", x = "Race", y = "Count") 

dist18_raceplot

# Data Vis. of Race Estimates for District 21
cvap_dist21 <- cvap_18 %>%
  filter(DIST=="Congressional District 21 (116th Congress)") %>%
  st_drop_geometry() %>%
  select(ALL_TOT18, ALL_AIA18, ALL_ASN18, ALL_BLK18, ALL_NHP18, ALL_WHT18, ALL_2OM18, ALL_HSP18) %>%
  rename("Total Population Est." = ALL_TOT18, 
         "Native American" = ALL_AIA18, 
         "Black" = ALL_BLK18,
         "Pacific Islander" = ALL_NHP18,
         "White" = ALL_WHT18,
         "Two or More Races" = ALL_2OM18,
         "Hispanic" = ALL_HSP18,
         "Asian" = ALL_ASN18)

cvap_dist21 <- cvap_dist21 %>% 
  pivot_longer(everything(),
               names_to='Race',
               values_to='Count')

cvap_dist21$Race <- reorder(cvap_dist21$Race, -cvap_dist21$Count)

dist21_raceplot <- cvap_dist21 %>%
  ggplot(aes(x = Race, y = Count, fill= Count)) +
  geom_bar(stat = "identity") +
  labs(title = "Population Estimate of District 21", x = "Race", y = "Count") 

dist21_raceplot
```

